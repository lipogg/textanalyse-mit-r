[["index.html", "Textanalyse mit R für die Geisteswissenschaften Über diesen Kurs", " Textanalyse mit R für die Geisteswissenschaften Lisa Poggel WiSe 2025/26 Freie Universität Berlin Über diesen Kurs Willkommen in meinem Seminar “Textanalyse mit R für die Geisteswissenschaften”! Hier findet ihr die Inhalte zu allen Sitzungen. Dieses Seminar vermittelt grundlegende praktische Kenntnisse der Textanalyse mit der Programmiersprache R. Der Fokus liegt auf der Verarbeitung und Analyse geisteswissenschaftlicher Daten. Das Seminar richtet sich insbesondere an Studierende ohne Programmiererfahrung und vermittelt neben Verfahren der Textanalyse und des Text Mining auch Grundlagen der Programmierung mit R. R kommt als besonders einstiegsfreundliche Programmiersprache vermehrt auch in geisteswissenschaftlichen Forschungsprojekten zur Anwendung, beispielsweise bei der quantitativen Textanalyse, in der digitalen Stilometrie, bei der Autorschaftserkennung oder zur Analyse und Visualisierung historischer Korrespondenznetzwerke. Das Seminar setzt keine Programmiererfahrung voraus. "],["warum-r.html", "Warum R? Was ist R überhaupt? R Thirst Traps", " Warum R? Was ist R überhaupt? R is a language and environment for statistical computing and graphics. Quelle: https://www.r-project.org/about.html Warum sollten Geisteswissenschaftler:innen eine Programmiersprache für “statistical computing” lernen? Kann man damit nicht nur Worthäufigkeiten zählen und Wortwolken erstellen? Und sind Wortwolken nicht irgendwie etwas “underwhelming”? In den letzten Jahren ist R neben Python zur meistgenutzten Programmiersprache im Bereich Data Science geworden. Data Scientists beschäftigen sich natürlich tatsächlich viel mit Statistik. Aber R ist viel mehr als “nur” Statistik. Die Anwendungsmöglichkeiten von R sind genauso vielfältig wie die Digital Humanities selbst. Und das nicht nur, weil die Digital Humanities selbst ein sehr vielseitiges Fach sind, über deren Definition immer noch kontrovers diskutiert wird (siehe zum Beispiel whatisdigitalhumanities.com). R hat eine aktive und riesige Community von Nutzer:innen, die immer neue sogenannte “Pakete” erstellen, die für bestimmte Anwendungen gemacht sind, wie zum Beispiel für die Analyse dramatischer Texte, die Stilometrie oder auch die Textanalyse ganz allgemein. Was man alles so mit R in den Digital Humanities anstellen kann, illustrieren die Beispiele im nächsten Abschnitt. R Thirst Traps Das klingt alles bisher noch sehr abstrakt. Deswegen hier ein paar ganz konkrete Anwendungsbeispiele von R im Bereich der Digital Humanities, die hoffentlich etwas Lust auf R machen: Web App, Geocoding, GIS, Queere Geschichte: https://www.mappingthegayguides.org/map/ Code zum Projekt: https://github.com/MappingtheGayGuides/MGG-App Rezeptionsforschung zu James Baldwin, Literaturgeschichte, Datenvisualisierung: https://tweetsofanativeson.com/Seattle-Public-Library-2023/ Code: https://github.com/JoeLollo21/Viral-Lit-Project Text Reuse und Intertextualität: https://americaspublicbible.org/ , https://americaspublicbible.supdigital.org/verse-viewer/?ref=Proverbs%2022%3A6 Code: https://github.com/lmullen/americas-public-bible Text Reuse in historischen Zeitschriften, Topic Modeling, Text Feature Extraction: https://viraltexts.org/ Code: https://github.com/rccordell/us-newspapers-1689-2009 ; https://github.com/ViralTexts/viral-texts-networks ; https://github.com/jonathandfitzgerald/Viral-Texts-R Topic Modeling: https://layeredlives.org/ Publikation zum Projekt: https://statsmaths.github.io/pdf/2022-layered-lives.pdf Named Entity Recognition und Textannotation: https://photogrammar.org Code: https://github.com/americanpanorama/photogrammar Korrespondenznetzwerk analysieren und visualisieren: https://www.jessesadler.com/project/dvdm-correspondence Code: https://github.com/jessesadler/dvdm-correspondence Quantitative Textanalyse von Shakespeare-Dramen, Datenbeschaffung: https://m-clark.github.io/text-analysis-with-R/shakespeare.html Dramenanalyse, Arbeit mit XML-TEI Dateien: https://quadrama.github.io/DramaAnalysis/tutorial/3/introduction.html Code: https://github.com/quadrama/DramaAnalysis Datenbeschaffung mithilfe von APIs (Codebeispiel): https://github.com/ThomasK81/ExploringDigitalHumanities/blob/master/RScripts/shortstories.R Textklassifikation (Codesammlung): https://github.com/kbenoit/newsmap Quantitative Inhaltsanalyse mit R, Kookkurrenzen von Charakteren in “Sherlock Holmes”: http://inhaltsanalyse-mit-r.de/netzwerke.html Lexikalische Vielfalt und Sentimentanalyse (Codesammlung): https://github.com/louismagowan/lyrics_analysis Lexikalische Ähnlichkeit von Romanen, Computational Linguistics, Stemming Publikation zum Projekt: https://piperlab.mcgill.ca/pdfs/Piper_NovelConversions.pdf Code: https://github.com/nan-da/Novel-Devotions Genreklassifikation, Topic Modeling, soziale Netzwerkanalyse, Part of Speech Tagging, uvm. Publikation: https://press.uchicago.edu/ucp/books/book/chicago/E/bo28465405.html Code: https://github.com/piperandrew/enumerations Computational Linguistics, Named Entity Recognition, Part of Speech Tagging: Publikation: https://amst.winter-verlag.de/article/AMST/2018/2/8 Code: https://github.com/nilsreiter/rereading-the-american-short-story Quantitative Linguistik, Korpuslinguistik: https://jupyter.korpus.cz/shiny/lukes/mda/ Code: https://github.com/dlukes/shiny-mda Digital Humanities Masterarbeit, in der R verwendet wird (Codesammlung): https://github.com/mikkosk/spectator_masters_thesis Noch eine Digital Humanities Masterarbeit (von mir): https://lipogg.shinyapps.io/soviet-ethnography/ Code: https://github.com/lipogg/soviet-ethnography Im Laufe des Semesters werden wir also nicht (nur) Wordclouds erstellen, sondern genuin geistes- bzw. literaturwissenschaftlichen Fragestellungen und Technologien behandeln, die für die geisteswissenschaftliche Arbeit relevant sind. Dabei sollen programmatische Zugriffe auf diese Fragestellungen natürlich traditionelle Analysemethoden nicht ersetzen, sondern diese produktiv ergänzen. "],["seminarplan.html", "Seminarplan", " Seminarplan Sitzung Nr. Datum Thema 1 14.10. Einstieg 2 21.10. R Basics I: Datentypen, Variablen und Operatoren 3, 4 28.10. und 04.11. R Basics II: Datenstrukturen 5 11.11. R Basics III: Kontrollstrukturen 6 18.11. R Basics IV: Funktionen und Pakete 7 25.11. R Basics Wiederholung 8 02.12. Textanalyse mit Quanteda I: Korpus, Tokens, Daten und Dateien 9 09.12. Textanalyse mit Quanteda II: Preprocessing und Reguläre Ausdrücke 10, 11 16.12. und 06.01. Textanalyse mit Quanteda III: Wortfrequenzanalysen 12 13.01. Part of Speech Tagging und Dependency Parsing mit UDPipe 13 20.01. Textanalyse Wiederholung 14 27.01. Named Entity Recognition 15, 16 03. und 10.02. Arbeit mit XML-TEI Dateien: XML, TEI und XPath Der Seminarplan ist erst einmal vorläufig. Je nach Lerntempo und Interessen werden wir das ein oder andere Thema mehr oder weniger vertiefen. Die Inhalte bauen grundsätzlich aufeinander auf: Zunächst beschäftigen wir uns mit sogenannten “unstrukturierten” Daten und später mit “(semi-)strukturierten” Daten. Nach einem Einstieg in R steigen wir in die Arbeit mit “rohem Text”, also Plaintext-Dateien, als Beispiel für unstrukturierte Daten ein und erarbeiten Grundkonzepte der quantitativen Textanalyse. Dabei werden wir auch diskutieren, was “geisteswissenschaftliche Daten” eigentlich sind. Danach behandeln wir zwei verschiedene Verfahren, wie Texte in R im Hinblick auf bestimmte Textinformationen strukturiert (man sagt auch “annotiert”) werden können: das automatisierte Erkennen von Wortarten (Part of Speech Tagging) und von “Entitäten” wie Personennamen und Ortsnamen (Named Entity Recognition). Zuletzt widmen wir uns XML-TEI-Dateien als Beispiel für die Analyse (semi-)strukturierter Textdaten. XML-TEI ist ein in den Digital Humanities weit verbreiteter Standard zur digitalen Darstellung von Texten, beispielsweise literarsichen Werken, archivalischen Quellen oder wissenschaftlichen Arbeiten. Mithilfe von XML-TEI können Textinformationen, zum Beispiel Metadaten und bestimmte Bestandteile des Textes, strukturiert dargestellt werden. Die vorgestellten Verfahren können wir natürlich in der kurzen Zeit nur sehr, sehr oberflächlich behandeln. Das Ziel ist es, dass ihr am Ende des Semesters Grundkonzepte des Programmierens in R und grundlegende Anwendungen der Programmiersprache im Bereich der Textanalyse kennt und euch die Fertigkeiten erarbeitet habt, fortgeschrittenere Themen eigenständig weiter zu vertiefen. Da wir viele Themen besprechen werden, erfordert dieses Seminar ein hohes Maß an Motivation und Durchhaltevermögen. Jede Woche wird es Übungsaufgaben geben. Die Bearbeitung der Übungsaufgaben ist verpflichtend und insbesondere zur Vor- und Nachbereitung der Einstiegssitzungen essentiell, denn sonst wird es sehr schwierig sein, später mitzukommen. Die Lernkurve ist demenstprechend steil: "],["lernziele.html", "Lernziele", " Lernziele Das Seminar ist als Praxisseminar konzipiert. Das heißt, dass der Fokus darauf liegt, anhand praktischer Übungsaufgaben und Fragestellungen das Coden in R zu erlernen. Das heißt aber nicht, dass wir nur Sachen auswendig lernen und Inhalte von einem Zusammenhang auf den anderen übertragen. Die kritische Analyse und Evaluation nicht nur von Code sondern auch von konkreten Verfahren ist essentiell für die Arbeit mit geisteswissenschaftlichen Daten. Nach diesem Seminar kennt ihr… Grundbegriffe und Konzepte der Programmierung mit R: Die Studierenden kennen den Unterschied zwischen verschiedenen Datentypen und Datenstrukturen und kennen die wichtigsten Operationen darauf. Sie haben ein Grundverständnis von der sinnvollen Strukturierung von R-Code und kennen wichtige Konventionen. Grundbegriffe und Verfahren der Textanalyse und -aufbereitung mit R: Die Studierenden kennen geeignete Verfahren zur Aufbereitung und Analyse von Plaintext-Dateien und XML-TEI-Dateien. Sie können mögliche Probleme, Vor- und Nachteile der verschiedenen Verfahren sowie ausgewählte Anwendungsgebiete der Verfahren benennen. Sie kennen relevante Richtwerte und Metriken zur Bewertung der Analyseergebnisse und haben ein elementares Verständnis der statistischen Grundlagen der angewandten Verfahren. Datenformate: Die Studierenden sind mit dem Aufbau von XML-TEI Dokumenten vertraut. Sie können zwischen verschiedenen Datenformaten unterscheiden. Suchtechniken für verschiedene Datenformate: Die Studierenden kennen die grundlegende Syntax von Regulären Ausdrücken und XPath. Nach diesem Seminar könnt ihr … Verfahren des Preprocessing und der Textanalyse in R anwenden: Die Studierenden können R-Code lesen und (je nach Vorkenntnissen) einfache bis fortgeschrittene Skripte zum Preprocessing und Analyse von Textdaten in R selbst schreiben. Sie können Fehler mithilfe von Debugging-Strategien selbst identifizieren und können Online-Ressourcen nutzen, um sich selbst Hilfe zu beschaffen. Sie können komplexen Code auf dem eigenen Computer reproduzieren. Sie sind routiniert im Umgang mit RStudio. Sie können einfache Ausdrücke zur Suche in Plaintext- und XML-TEI-Dateien mithilfe von Regulären Ausdrücken und XPath schreiben und einsetzen. Auswirkungen der angewandten Verfahren evaluieren: Die Studierenden können evaluieren, wie sich verschiedene Entscheidungen und Verfahren des Preprocessing auf die Analyse eines Textkorpus’ auswirken. Sie können identifizieren, welche Preprocessing-Schritte die Analyseergebnisse verbessern können. Aussagekraft der Ergebnisse kritisch bewerten: Die Studierenden können die Ergebnisse der verschiedenen Analyse-, Such und Extraktionsverfahren im Hinblick auf die Preprocessingentscheidungen, die Qualität und Zusammensetzung des Korpus kritisch bewerten. "],["organisatorisches.html", "Organisatorisches", " Organisatorisches Hier findet ihr Informationen zu Teilnahmemodalitäten, Prüfungsleistungen und Kommunikation. Teilnahmeschein: Aktive Teilnahme: n-2 Sitzungen Wöchentliche Übungsaufgaben: Lösungen Montagabend vor jeder Stunde an mich schicken (l.poggel@fu-berlin.de). Übungen schicke ich euch per Mail jede Woche Mittwoch. Ein Kahoot-Quiz erstellen und moderieren. Login über https://kahoot.com/ Leistungsschein: Wie Teilnahmeschein Zusätzlich ein eigenständiges Projekt (ersetzt die Hausarbeit): Ihr plant und implementiert auf der Grundlage der Inhalte aus diesem Seminar ein kleines Digital Humanities Projekt. Im Laufe der Bearbeitung eurer Fragestellung erstellt ihr ein kleines Programmierportfolio mit allen Skripten, die ihr im Rahmen des Projekts erstellt habt. Das Portfolio sendet ihr als Zip-Ordner bis zum 31.03.2026 an l.poggel@fu-berlin.de. Die Anforderungen, Projektbeispiele und die Bewertungsgrundlage für das Portfolio besprechen wir rechtzeitig im Laufe des Semesters. Kommunikation: Bei Fragen, Kritik oder falls ihr mal eine Sitzung nicht kommen könnt, schreibt mir eine E-Mail an l.poggel@fu-berlin.de. Um eine Sprechstunde zu vereinbaren, könnt ihr mich gern vor oder nach den Sitzungen ansprechen oder mir eine E-Mail schreiben. Regelungen zur Nutzung von KI-Tools KI-Tools dürfen in diesem Seminar bei der Bearbeitung der Übungsblätter und der Projektarbeit ausschließlich zum Debuggen verwendet werden. Bei der Projektarbeit könnt ihr für Anwendungen, die über die im Seminar besprochenen Themen hinausgehen, in manchen Fällen auch KI-Tools zur Unterstützung verwenden, ihr müsst dies aber vor der Abgabe mit mir absprechen und im Dokumentationstext nach den Vorgaben der Eigenständigkeitserklärung des Fachbereichs Philosophie und Geisteswissenschaften kenntlich machen. Die ausgefüllte und unterschriebene Eigenständigkeitserklärung ist zusammen mit der Projektarbeit einzureichen. Bitte seid euch darüber bewusst, dass die Verwendung von KI-Tools ohne entsprechenden Hinweis einen Täuschungsversuch darstellt. Bewertungskriterien für das Abschlussprojekt: Umfang: Programmierportfolio, bestehend aus mindestens zwei verschiedenen R Skripten und einem Dokumentationstext, der die Fragestellung, das Korpus, den Forschungsstand und die gewählten Verfahren vorstellt und begründet, sowie die Ergebnisse in Bezug auf die Fragestellung auswertet und kritisch diskutiert. Der Umfang der Dokumentationstextes (exklusive Code) sollte 4-8 Seiten (ca. 1200-3000 Wörter) entsprechen. Abgabefrist: 31.03.2026 Abgabeformat: Programmierportfolio als Zip-Ordner Beispielportfolio: Skript 1: Preprocessing. Vorbereitetes Korpus wird in RDS-Datei gespeichert. Skript 2: Analyse mit quanteda, UDPipe (oder Named Entity Recognition). Das Korpus wird aus der RDS-Datei eingelesen. Dokumentation als RMarkdown-Dokument oder PDF Bewertungsskala: Note Erläuterung 1.0-1.3 Alle formalen Kriterien werden eingehalten. Die Forschungsfrage ist sinnvoll und mithilfe der gewählten Preprocessing- und Analyseverfahren sehr gut beantwortbar. Es gibt dabei unter den im Kurs kennengelernten Verfahren keine besser geeigneten Verfahren zur Beantwortung der Fragestellung. Die Wahl der verwendeten Verfahren, Vor- und Nachteile, die Aussagekraft sowie mögliche Auswirkungen auf die Beantwortung der Fragestellung werden kritisch diskutiert. Die Aussagekraft des Analyseverfahrens wird kritisch diskutiert. Die Ergebnisse werden in Bezug zum aktuellen Forschungsstand gesetzt. Der Code ist ausführlich kommentiert. Fremder Code wird nur dann verwendet, wenn der Code für die Umsetzung von Aufgaben, die über die Inhalte im Seminar hinausgehen, gebraucht wird, oder, wenn der Code eine Verbesserung zu den im Seminar vorgestellten Vorgehen darstellt. Fremder Code wird immer zitiert. Der Code produziert keine Fehlermeldungen und folgt immer gängigen stilistischen Konventionen und Regeln. 1.3-2.3 Alle formalen Kriterien werden eingehalten. Die Fragestellung ist sinnvoll und mithilfe der gewählten Preprocessing- und Analyseverfahren beantwortbar, aber es gibt ein besser geeignetes Verfahren. Die Wahl des Verfahrens wird begründet, aber die Begründung ist nicht gänzlich überzeugend oder weniger wichtige Konsequenzen der Entscheidung werden nicht diskutiert. Die Aussagekraft des Analyseverfahrens wird kritisch diskutiert. Die Ergebnisse werden in Bezug zum aktuellen Forschungsstand gesetzt. Der Code ist ausführlich kommentiert. Fremder Code wird nur dann verwendet, wenn der Code für die Umsetzung von Aufgaben, die über die Inhalte im Seminar hinausgehen, gebraucht wird, oder, wenn der Code eine Verbesserung zu den im Seminar vorgestellten Vorgehen darstellt. Fremder Code wird immer zitiert. Der Code produziert keine Fehlermeldungen und folgt zumeist gängigen stilistischen Konventionen und Regeln. 2.3-3.3 Alle formalen Kriterien werden eingehalten. Die Fragestellung ist sinnvoll und mithilfe der gewählten Preprocessing- und Analyseverfahren beantwortbar, aber es gibt ein besser geeignetes Verfahren. Die Wahl des Verfahrens wird begründet, aber die Begründung ist nicht überzeugend. Der Code ist an den wichtigsten Stellen kommentiert. Fremder Code wird nur dann verwendet, wenn der Code für die Umsetzung von Aufgaben, die über die Inhalte im Seminar hinausgehen, gebraucht wird, oder, wenn der Code eine Verbesserung zu den im Seminar vorgestellten Vorgehen darstellt. Fremder Code wird immer zitiert. Der Code produziert keine Fehlermeldungen. 3.3-4.0 Formale Kriterien werden zumeist eingehalten. Die Fragestellung ist teilweise mithilfe der gewählten Preprocessing- und Analyseverfahren beantwortbar. Die Wahl des Verfahrens wird begründet, aber die Begründung ist nicht überzeugend. Fremder Code wird immer zitiert. Der Code produziert keine Fehlermeldungen. ab 4.0 Formale Kriterien werden zumeist eingehalten. Die Fragestellung ist teilweise mithilfe der gewählten Preprocessing- und Analyseverfahren beantwortbar. Die Wahl des Verfahrens wird nicht begründet. Fremder Code wird immer zitiert. Der Code produziert keine Fehlermeldungen. 5.0 Formale Kriterien werden nicht eingehalten. Der Code ist nicht ausführbar und enthält schwerwiegende Fehler. Die Fragestellung ist nicht sinnvoll gewählt und die gewählten Preprocessing- und Analyseverfahren sind nicht geeignet, um die Fragestellung zu bearbeiten. "],["hilfe.html", "Hilfe!!", " Hilfe!! Oft kommt es beim Coden zu komischen Fehlermeldungen, die mehr verwirren als helfen. Häufig steckt aber ein ganz simpler Flüchtigkeitsfehler dahinter. In diesem Fall gilt: 1. Syntax und Rechtschreibung überprüfen. Fehlt vielleicht nur eine Klammer? Ist die Variable wirklich richtig geschrieben? Sind wirklich alle notwendigen Pakete installiert und geladen? 2. Fehlermeldung kopieren und googeln. Bestimmt hatte schonmal jemand anderes dasselbe Problem und bestenfalls findet sich eine Lösung auf https://stackoverflow.com/ oder in einem anderen Forum. 3. ChatGPT fragen. Das Codesnippet an ChatGPT senden und nach möglichen Fehlern fragen. 4. R Hilfeseiten aufrufen. Mit dem ? und dem ?? Operator können über die Konsole die Dokumentation zu konkreten Funktionen aufgerufen werden. Das kann nützlich sein, um beispielsweise zu überprüfen, welchen Datentyp die Funktion als Input nimmt. Wenn mit ?funktionsname keine oder nicht die richtige Dokumentationsseite gefunden wird, kann alternativ mit ?paketname::funktionsname nach einer Funktion aus einem konkreten Paket gesucht werden. Weitere Informationen zu den R Hilfeseiten: https://www.r-project.org/help.html Manchmal macht das Skript aber auch einfach nicht das, was es soll, ohne, dass eine Fehlermeldung entsteht. In diesem Fall liegt wahrscheinlich ein logischer Fehler im Programmablauf vor. Für diesen Fall gibt es eine Strategie, die Rubber Ducking oder Quietscheentchen-Debugging genannt wird. 5. Rubber Ducking oder Quietscheentschen-Debugging. Wenn nichts mehr hilft, hilft nur eins: Den Code einer Person, die nichts davon versteht - oder eben einem Quietscheentchen, Zeile für Zeile erklären. Dabei fallen oft logische Fehler auf, die das Problem verursachen. 6. Hilfe holen. Falls ihr im Laufe des Seminars ein Problem habt, das ihr selbst nicht lösen könnt, könnt ihr einen Screenshot für die nächste Sitzung mitbringen oder mir eine E-Mail an l.poggel@fu-berlin.de schreiben. Falls die Konsole (Fenster Console im RStudio) plötzlich + statt &gt; anzeigt oder sich ein Prozess durch Klick auf das rote “Stop”-Symbol nicht abbrechen lässt: Tastenkombination Ctrl (Control) + C (bzw. Strg + C). Zuletzt kann es natürlich auch vorkommen, dass euch ein Inhalt aus dem Seminar nicht ganz klar ist oder ihr ein weiterführendes Interesse an einem Thema habt. Lehrbücher und Ressourcen zum Nachlesen findet ihr unter “Ressourcen”. "],["ressourcen.html", "Ressourcen", " Ressourcen Allgemein: Offizielle R Handbücher: https://cran.r-project.org/manuals.html Wickham, Hadley, Çetinkaya-Rundel, Mine und Grolemund, Garrett (2023). R for Data Science (=Official Tidyverse Book): https://r4ds.hadley.nz/ Schmidt, Ben (ongoing). Humanities Data Fundamentals: https://hdf.benschmidt.org/R/ Van Atteveldt, Wouter, Trilling, Damian und Arcila Calderón, Carlos (2022). Computational Analysis of Communication: https://cssbook.net/ Stoltz, Dustin S. und Taylor, Marshall A. (2024). Mapping Texts. Computational Text Analysis for the Social Sciences, https://global.oup.com/academic/product/mapping-texts-9780197756881 Sammlung von R “Cheatsheets”: https://github.com/rstudio/cheatsheets/tree/main Lehrbuch-Klassiker (für Grundlagen, bei speziellen Anwendungen zum Teil nicht mehr aktuell): Andresen, Melanie (2024). Computerlinguistische Methoden für die Digital Humanities, https://doi.org/10.24053/9783823395799 (hervorragendes Lehrbuch vor allem zum theoretischen und mathematischen Hintergrund der verschiedenen Methoden) Arnold, Taylor und Tilton, Lauren (2024). Humanities Data in R. Exploring Networks, Geospatial Data, Images, and Text: https://doi.org/10.1007/978-3-031-62566-4 Jockers, Matthew und Thalken, Rosamond (2020). Text Analysis with R for Students of Literature: https://doi.org/10.1007/978-3-030-39643-5 Desagulier, Guillaume (2017). Corpus Linguistics and Statistics with R: https://doi.org/10.1007/978-3-319-64572-8 Levshina, Natalia (2015). How to Do Linguistics with R: https://doi.org/10.1075/z.195 Textanalyse mit Quanteda: Offizielle Quanteda-Dokumentationsseiten: https://quanteda.io/ Offizielles Quanteda-Tutorial: https://tutorials.quanteda.io/ Replikation des Codes aus Levshinas “Text Analysis with R for Students of Literature” mithilfe von Quanteda: https://quanteda.io/articles/pkgdown/replication/digital-humanities.html Video-Tutorial zu Preprocessing und Textanalyse mit R von Kasper Welbers: https://www.youtube.com/playlist?list=PL-i7GM-A1wBZYRYTpem7hNVHK3hSV_1It Kapitel 10: “Text as Data” aus “Computational Analysis of Communication”: https://cssbook.net/content/chapter10.html Kapitel 6: “From Text to Numbers” aus “Mapping Texts”: https://global.oup.com/academic/product/mapping-texts-9780197756881 Datenvisualisierung mit ggplot2: Healy, Kieran (2019). Data Visualization. A Practical Introduction, https://socviz.co/ Wickham, Hadley (2016). ggplot2. Elegant Graphics for Data Analysis, https://ggplot2-book.org/ ggplot2-Dokumentationsseiten: https://ggplot2.tidyverse.org/; https://ggplot2.tidyverse.org/articles/ggplot2.html Online-Tool das dabei hilft, eine passende Visualisierung zu finden, mit Links zu den Dokumentationsseiten geeigneter R Funktionen: https://www.data-to-viz.com/ Statistik: (grundlegend) Handl, Andreas und Kuhlenkasper, Torben (2018). Einführung in die Statistik. Theorie und Praxis mit R: https://doi.org/10.1007/978-3-662-56440-0 (grundlegend) Gries, Stefan (2021). Statistics for Linguistics with R: https://doi.org/10.1515/9783110718256 (grundlegend) Blitzstein, Joe. Vorlesungsvideos, interaktiver Kurs und Buch Statistics 110: Probability, https://projects.iq.harvard.edu/stat110/home (fortgeschritten) Kroonenberg, Pieter (2021). Multivariate Humanities: https://doi.org/10.1007/978-3-030-69150-9 (fortgeschritten) Handl, Andreas und Kuhlenkasper, Torben (2017). Multivariate Analysemethoden. Theorie und Praxis mit R: https://doi.org/10.1007/978-3-662-54754-0 Hintergrund Preprocessing und Natural Language Processing (POS Tagging, Dependency Parsing, NER,…): Jurafsky, Daniel und Martin, James H. (2025). Speech and Language Processing, https://web.stanford.edu/~jurafsky/slp3/ (insbesondere Kapitel 2, 8, 17, 18). Andresen, Melanie (2024). Computerlinguistische Methoden für die Digital Humanities, https://doi.org/10.24053/9783823395799 Grimmer, Justin, Roberts, Margaret E. und Stewart, Brandon M. (2022), Text as Data. A New Framework for Machine Learning and the Social Sciences, https://fu-berlin.primo.exlibrisgroup.com/permalink/49KOBV_FUB/1v1tp5h/alma9960725495502883 Biemann, Chris, Heyer, Gerhard und Quasthoff, Uwe (2013). Wissensrohstoff Text. Eine Einführung in das Text Mining, https://doi.org/10.1007/978-3-658-35969-0 (insbesondere Kapitel 1, 2). Theorie (wird fortlaufend ergänzt): Gius, Evelyn und Jacke, Janina (2022). Are Computational Literary Studies Structuralist?, in: Journal of Cultural Analytics 7, no. 4, https://doi.org/10.22148/001c.46662. (Woche 1) Pichler, Axel und Reiter, Nils (2021), Zur Operationalisierung literaturwissenschaftlicher Begriffe in der algorithmischen Textanalyse, in: Journal of Literary Theory 15, no. 1-2, https://doi.org/10.1515/jlt-2021-2008. (W1) Bhattacharyya, Sayan (2021). Text Analysis for Thought in the Black Atlantic, in: Kelly Baker Josephs und Roopika Risam, The Digital Black Atlantic, pp. 77-83, https://muse.jhu.edu/book/84470. (W1) Stoltz, Dustin und Taylor, Marshall (2024). Mapping Texts. S. XIII und Ch. 1: Text in Context, https://doi.org/10.1093/oso/9780197756874.001.0001. (W1) Pichler, Axel und Reiter, Nils (2022). From Concepts to Texts and Back: Operationalization as a Core Activity of Digital Humanities, https://culturalanalytics.org/article/57195 Risam, Roopika (2019). New Digital Worlds. Postcolonial Digital Humanities in Theory, Praxis, and Pedagogy. Ch. 1: The Stakes of Postcolonial Digital Humanities (insb. Abschnitt World Making in Digital Humanities), https://fu-berlin.primo.exlibrisgroup.com/permalink/49KOBV_FUB/1v1tp5h/alma9961448530002883. Bubenhofer, Noah und Scharloth, Joachim (2013). Korpuslinguistische Diskursanalyse, in: Ulrike Hanna Meinhof, Martin Reisigl und Ingo Warnke (Hrsg.), Diskurslinguistik im Spannungsfeld von Deskription und Kritik, S. 147-167. https://doi.org/10.1524/9783050061047.147 Bode, Katherine (2017), The Equivalence of “Close” and “Distant” Reading; or, Toward a New Object for Data-Rich Literary History, https://doi.org/10.1215/00267929-3699787. Kleymann, Rabea (2022). Datendiffraktion: Von Mixed zu Entangled Methods in den Digital Humanities, https://doi.org/10.17175/sb005_008. Alessandro Lenci und Magnus Sahlgren (2023). Distributional Semantics, Ch. 1: From Usage to Meaning. The Foundations of Distributional Semantics, pp. 3-25, https://doi.org/10.1017/9780511783692.002 (Woche 9) Eve, Martin Paul (2022). The Digital Humanities and Literary Studies. Introduction, https://doi.org/10.1093/oso/9780198850489.003.0001 (für Skeptiker:innen) Bond, Sarah, Long, Hoyt und Underwood, Ted (2017). ‘Digital’ Is Not the Opposite of ‘Humanities’, https://www.chronicle.com/article/digital-is-not-the-opposite-of-humanities/. (für Skeptiker:innen) Glossar der Zeitschrift für digitale Geisteswissenschaften (mit Beiträgen zu Theorie, Operationalisierung, Daten, …): https://zfdg.de/wp_2023_001. Literaturhinweise zu den verschiedenen Analysemethoden findet ihr in den optionalen ausklappbaren Abschnitten im jeweiligen Kapitel. Einige Digital Humanities Zeitschriften (für die eigene Recherche): Zeitschrift für digitale Geisteswissenschaften, https://zfdg.de/ Digital Scholarship in the Humanities, https://academic.oup.com/dsh Digital Humanities Quarterly, https://www.digitalhumanities.org/dhq/ Journal of Cultural Analytics, https://culturalanalytics.org/ Journal of Computational Literary Studies, https://jcls.io/ Journal of Digital History, https://journalofdigitalhistory.org/ International Journal of Digital Humanities, https://link.springer.com/journal/42803 Digital Humanities Benelux Journal, https://journal.dhbenelux.org/ Digital Studies / Le champ numérique, https://www.digitalstudies.org/ Humanités Numériques, https://journals.openedition.org/revuehn/ Volltextrepositorien mit Texten im Plaintext- oder XML-TEI-Format: https://wikisource.org/ (Plaintext, PDF, eBook-Formate) https://www.projekt-gutenberg.org/ (Volltexte nur online, zum Download ist Webscraping erforderlich) https://gutenberg.org (Plaintext, HTML, eBook-Formate) https://textgridrep.org/ (XML-TEI, Bildformate) https://archive.org/ (Volltexte im Plaintextformat aber häufig mittels OCR erstellt und in fragwürdiger Qualität) Datensätze und Korpora für die Textanalyse (wird fortlaufend ergänzt): Korpora, Editionen und Repositorien im Text+ Registry: https://registry.text-plus.org/ Datensätze im Social Sciences and Humanities Open Marketplace: https://marketplace.sshopencloud.eu/search?categories=dataset Datensätze im Hamburger Zentrum für Sprachkorpora: https://www.fdr.uni-hamburg.de/communities/hzsk/ Links zu historischen Textkorpora in der Perseus Digital Library: https://www.perseus.tufts.edu/hopper/collections Links zu verschiedenen Listen von DH Korpora und Datensätzen (unter “Resources for finding humanities data”): https://cdh.princeton.edu/programs/humanities-data-new/; https://guides.lib.ua.edu/datasources/humanities Journal of Open Humanities Data, https://openhumanitiesdata.metajnl.com/articles Deutsches Textarchiv: https://www.deutschestextarchiv.de/download European Literary Text Collection (ELTeC): https://github.com/COST-ELTeC/ELTeC Download über Github, z.B. für die deutschen Texte: https://github.com/COST-ELTeC/ELTeC-deu Assoziiertes Projekt: https://www.distant-reading.net/ DraCor (europäische Dramen in vielen verschiedenen Sprachen): https://dracor.org/ SlaveVoyages Datenbank: https://www.slavevoyages.org/american/downloads#intra-american-database-downloads/0/en/ Digitale Sammlung Deutscher Kolonialismus: https://www.deutschestextarchiv.de/dsdk/ HathiTrust derived datasets: https://analytics.hathitrust.org/deriveddatasets; https://htrc.atlassian.net/wiki/spaces/COM/pages/43287791/HTRC+Derived+Datasets Somar Social Media Archive: https://socialmediaarchive.org/ Digitale Sammlungen der Österreichischen Nationalbibliothek: https://labs.onb.ac.at/de/datasets/ Verzeichnis linguistischer Korpora (Daten zu den Korpora sind aber z.T. nicht mehr aktuell): https://www.lancaster.ac.uk/fass/projects/corpus/cbls/corpora.asp Datendienst des Deutschen Literaturarchivs Marbach: https://www.dla-marbach.de/katalog/dla-dataplus/ The Hansard Corpus (linguistisch annotierte britische Parlamentsreden 1802-2023): https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857509 Verzeichnis wissenschaftliche Sammlungen an Hochschulen und Universitäten: https://portal.wissenschaftliche-sammlungen.de/ Verzeichnis kulturwissenschaftlicher Datensätze: https://nfdi4culture.de/resources/repositories.html Datensätze der Australian Research Data Commons: https://ardc.edu.au/researcher/accelerate-your-hass-and-indigenous-research/ Sammlung tabellarischer Datensätze mit ausführlichen Erläuterungen zum Kontext der Daten und R-Programmierübungen: https://www.responsible-datasets-in-context.com/datasets.html Verschiedene Universitäten weltweit sammeln außerdem Datensätze und Forschungsdaten in eigenen Forschungsdatenrepositorien, zum Beispiel: Harvard Dataverse (aktuell mit Stand Feb. 2025 37.000 Datensätze für das Thema “Arts and Humanities”), https://dataverse.harvard.edu/ Heidelberg Open Research Data (heiDATA; kleine Sammlung von Volltexten und XML-TEI-Editionen von Forschungsprojekten an der Uni Heidelberg, z.B. digitale Editionen der Kaiserchronik, des Maltechnik-Notizbuchs von Hans Emmenegger, der Korrespondenz von Nicodemus Frischlin, Index zu Artikeln der chinesischen Zeitschrift Shenbao, Metadaten zu allen Werken von Abou Naddara, uvm.), https://heidata.uni-heidelberg.de/dataverse/root Einen Überblick über weitere solche “Dataverses” findet ihr unter https://dataverse.org/ Zuletzt arbeiten auch außeruniversitäre Forschungsinstitute und die Akademien der Wissenschaften in den verschiedenen Bundesländern an digitalen Editionen und anderen Forschungsprojekten: Edition Humboldt Digital an der Berlin-Brandenburgischen Akademie der Wissenschaften: https://edition-humboldt.de/ Digitale Reiseberichte der Frühen Neuzeit in Sachsen an der Sächsischen Akademie der Wissenschaften : https://reise.isgv.de/ Forschungsprojekte an der Akademie der Wissenschaften und der Literatur Mainz: https://lod.academy/site/projects Digitale Ressourcen des Max Planck Instituts für Wissenschaftsgeschichte (darunter z.B. auch eine Sammlung frühneuzeitlicher Rezepte und eine Datenbank mit Metadaten zu Büchern in chinesischen öffentlichen Einrichtungen des 14. bis 21. Jahrhunderts): https://www.mpiwg-berlin.mpg.de/de/publikationen-ressourcen/digitale-ressourcen "],["installation-und-setup.html", "Installation und Setup", " Installation und Setup Egal, welches Betriebssystem: Erst R installieren, dann RStudio! R installieren (Mac: Intel oder Silicon!) https://cran.r-project.org/ Mac: Zusätzlich XQuartz installieren: https://www.xquartz.org/ RStudio installieren (RStudio ist jetzt Posit): https://posit.co/download/rstudio-desktop/ Wenn alles installiert ist, öffnet RStudio. "],["orientierung-im-rstudio.html", "Orientierung im RStudio", " Orientierung im RStudio "],["r-basics-i-datentypen-variablen-und-operatoren.html", "1 R Basics I: Datentypen, Variablen und Operatoren 1.1 Grundlegende Begriffe 1.2 Style Guide 1.3 Kommentare 1.4 Datentypen 1.5 Operatoren 1.6 Variablen 1.7 Operatorpräzedenz Quellen", " 1 R Basics I: Datentypen, Variablen und Operatoren 1.1 Grundlegende Begriffe Begriff Englische Entsprechung Definition (im R-Kontext) Objekt Object Alles: Funktionen, Variablen, Datenstrukturen,.. Anweisung Statement Syntaktische Einheit, die Aktionen beschreibt, die von einem Computer ausgeführt werden können. Wenn die Anweisung ausgeführt wird, wird die Aktion veranlasst und der Zustand des Speichers wird geändert. Zuweisung Assignment Besondere Art von Anweisung, bei der einer Variable ein bestimmter Wert zugeordnet wird. Dabei wird ein Name festgelegt, der fortan für diesen Wert und für den Speicherplatz, in dem der Wert gespeichert wird, steht. Ausdruck Expression Syntaktische Einheit, die zu einem Wert evaluiert (ausgewertet) werden kann. Ein Ausdruck ist immer Teil einer Anweisung. Ausdrücke stehen auf der rechten Seite von Zuweisungen: x &lt;- Ausdruck. Ausdrücke haben immer einen Typ, der dem Datentyp des Werts entspricht, zu dem sie evaluiert werden, z.B. 3 == 4 ist ein Ausdruck vom Typ boolean. Aussage Proposition In der Aussagenlogik ein sprachliches Gebilde, von dem es sinnvoll ist zu sagen, dass es entweder wahr oder falsch ist (Aristoteles). Im R-Kontext ein Ausdruck, der entweder zu TRUE oder zu FALSE evaluiert werden kann. Auswerten Evaluate Der Computer liest einen Ausdruck und wertet diesen aus: Er berechnet etwas und liefert einen Wert. Ausführen Execute Der Computer liest eine Anweisung und führt diese aus: Er macht etwas und ändert den Zustand des Speichers. Ausgeben Output/Print Das Ergebnis einer Berechnung oder die Ausgabe einer Funktion wird auf der Konsole angezeigt. Die Definitionen sind angelehnt an Venables et al. (2023), Wickham (2019) und Reussner (2016). 1.2 Style Guide Anders als beispielsweise in Python gibt es in R keinen allgemein anerkannten “Coding Style”, also keine über die Syntaxregeln hinausgehenden Vorgaben, wie Code am besten geschrieben wird. Es gibt allerdings einige breit akzeptierte Empfehlungen. Wir richten uns in diesem Kurs nach dem “Tidyverse Style Guide” von Hadley Wickham: https://style.tidyverse.org/. 1.3 Kommentare Um den eigenen Code für andere verständlicher zu gestalten und sich selbst an seinen Code zu erinnern, sollte man diesen immer gut kommentieren. # Das ist ein Kommentar 1.4 Datentypen In R ist ganz grundsätzlich alles ein Objekt: ein Wort, eine Zahl, ein Vektor, eine Liste, eine Variable und sogar Funktionen (lernen wir alles später), all das wird in R als Objekt behandelt. Wie auch in der realen Welt haben verschiedene Objekte verschiedene Eigenschaften und sie können für verschiedene Zwecke und auf verschiedene Weise verwendet werden. Das hängt davon ab, um was für eine Art Objekt es sich handelt: ein Objekt vom Typ “Lampe” kann man anschalten und ausschalten, mathematische Objekte wie Zahlen kann man addieren und dividieren, ein Auto kann fahren, parken oder tanken. In R haben wir es natürlich nicht mit realen Objekten zu tun, sondern eigentlich mit “Datenobjekten”. In R gibt es vier grundlegende Datentypen (und zwei, die wir jetzt erstmal ignorieren): character (auch “character string”): Zeichenkette integer: Ganzzahl numeric (auch “double”): Gleitkommazahl logical (auch “boolean”): Boolescher Wahrheitswert Character ist kurz für “character string”; in anderen Programmiersprachen heißt dieser Datentyp daher oft “string”. In R wird jeder Ausdruck, der von Anführungszeichen umgeben ist, als Zeichenkette (character) interpretiert. Double ist, ähnlich wie bei character und string, der allgemeine Name für den Datentyp numeric. Der Default-Datentyp für Zahlen ist in R numeric. Um eine Zahl als Integer zu definieren, kann ein großes L an die Zahl angefügt werden. Logical steht für die beiden Werte TRUE und FALSE. Sie werden auch als Boolesche Wahrheitswerte bezeichnet (-&gt; kennt ihr ggf. aus der Aussagenlogik). Für “Datentyp” kann man auch kurz “Typ” sagen. Ein paar Beispiele: 2 2L 345682389 4.6 # Punkt statt Komma! &quot;4.6&quot; TRUE FALSE &quot;Hello World&quot; # Anführungszeichen! &quot;Ein ganz langer Satz! Mit mehreren Satzzeichen. Und einer Zahl: 34.&quot; &quot; &quot; Den Datentyp eines Objekts könnt ihr z.B. mit der Funktion typeof() abfragen. Wenn ihr jede Zeile nacheinander in ein R Skript kopiert und ausführt, wird auf der Konsole (Fenster Console im RStudio) der Wert ausgegeben, der hier von #&gt; angeführt wird. typeof(2) #&gt; [1] &quot;double&quot; typeof(2L) #&gt; [1] &quot;integer&quot; typeof(4.6) #&gt; [1] &quot;double&quot; typeof(&quot;Hello World&quot;) #&gt; [1] &quot;character&quot; typeof(TRUE) #&gt; [1] &quot;logical&quot; Verständnisfragen: Ist ” ” auch ein Zeichen? Haben 4.6 und “4.6” denselben Datentyp? Welchen Datentyp hat der Satz “Ein ganz langer Satz! …”? Style Tip: Für Zeichenketten können einfache oder doppelte Anführungszeichen verwendet werden. Wickham empfiehlt, für Zeichenketten doppelte Anführungszeichen zu verwenden, außer, wenn diese selbst Anführungszeichen beinhalten, hier werden beide Anführungszeichen wie folgt kombiniert: ‘Text mit “Anführungszeichen”’. 1.5 Operatoren Je nachdem, welchen Datentyp ein oder mehrere Objekte in R haben, können diese Objekte auf verschiedene Weise mithilfe von Operatoren manipuliert werden. Arithmetische Operatoren sind aus der Schulmathematik bekannt. Es handelt sich dabei um Operatoren wie -, +, *, / sowie %% und %/%. Beachtet, dass der Divisionsoperator / nur für numerics definiert ist. Für die Division zweier integers wird ein spezieller Divisionsoperator, %/%, verwendet. %% ist der modulo Operator, damit kann bei einer Division der Rest berechnet werden. ^ oder ** wird zum Exponieren verwendet. 5 + 4 #&gt; [1] 9 10 / 5 #&gt; [1] 2 3 * 6.3 #&gt; [1] 18.9 10 %% 5 #&gt; [1] 0 10^2 #&gt; [1] 100 10**2 #&gt; [1] 100 Verständnisfragen: Was passiert, wenn wir \"Hallo\" + \"Welt\" ausführen? Welche Datentypen in R erlauben arithmetische Operationen? Logische Operatoren ermöglichen es, Werte zu vergleichen und die Richtigkeit einer logischen Aussage zu überpüfen. Die Vergleichsoperatoren &lt;, &gt;, &lt;=, &gt;= sind allgemein bekannt. Außerdem sind folgende Operatoren wichtig: Operator Bedeutung == genau gleich != ungleich !x nicht x x ⎮ y x oder y x &amp; y x und y x ⎮⎮ y x oder y in Kontrollstrukturen x &amp;&amp; y x und y Kontrollstrukturen Beispiele: -5 &lt; -10 #&gt; [1] FALSE 5 &gt;= 5 #&gt; [1] TRUE 3 != 5 #&gt; [1] TRUE &quot;Hallo&quot; != &quot;Hello&quot; #&gt; [1] TRUE 3 == 3 &amp; &quot;c&quot; == &quot;c&quot; #&gt; [1] TRUE 3 == 3 | &quot;c&quot; == &quot;a&quot; #&gt; [1] TRUE &quot;Eine Rose ist eine Pflanze&quot; == &quot;Eine Rose ist keine Pflanze&quot; #&gt; [1] FALSE Verständnisfragen: Warum wird der Ausdruck 3 == 3 &amp; \"c\" == \"c\" zu TRUE evaluiert? Warum wird auch der Ausdruck 3 == 3 | \"c\" == \"a\" zu TRUE evaluiert? Was passiert im letzten Beispiel? Der Wahrheitswert, zu dem ein Ausdruck mit einem logischen Operator in R evaluiert wird, lässt sich aus einer sogenannten Wahrheitstabelle ablesen. Für zwei Ausdrücke A und B und die logischen Operatoren &amp; und | lassen sich die folgenden Kombinationen als Wahrheitstabelle darstellen: Verständnisfragen: A sei der Ausdruck 3 == 3 &amp; \"c\" == \"c\" und B sei der Ausdruck -5 &lt; -10. Ist A &amp; B wahr oder falsch? Ist A | B wahr oder falsch? In Kontrollstrukturen (lernen wir noch) werden anstelle von &amp; und | die beiden Operatoren &amp;&amp; und || verwendet. Das hat den Grund, dass die Objekte in einem Ausdruck mit &amp;und | bei “elementweise” ausgewertet werden. Bei der Auswertung von Ausdrücken mit &amp;&amp; und || wird dagegen nur das erste Element ausgewertet. Dieses Verhalten heißt deswegen auch “lazy evaluation”. Das Verhalten ist bei einfachen Ausdrücken nicht bemerkbar, aber es wird relevant, wenn die Operatoren auf Datenstrukturen anstelle von einzelnen Werten wie bisher angewendet werden. Für die beiden Operatoren &amp;&amp; und || sind die Wahrheitstabellen also nur dann zu den Wahrheitstabellen der Operatoren &amp; und | analog, wenn einzelne Werte verglichen werden. Darauf werden wir in der kommenden Stunde noch einmal zurückkommen, wenn wir Objekte kennengelernt haben, die aus mehreren Elementen bestehen. Im nächsten Abschnitt werden wir einen weiteren Operator kennenlernen, den sogenannten Zuweisungsoperator &lt;- bzw. =. Daneben gibt es die Zugriffsoperatoren [], [[]], [:] und $, mit denen Operationen auf Datenstrukturen ausgeführt werden können. Diese Operatoren lernen wir in der nächsten Stunde kennen, wenn wir uns mit Datenstrukturen beschäftigen. 1.6 Variablen Angenommen, wir wollen den Wert, der ausgegeben wird, wenn der Ausdruck 3 == 3 &amp; \"c\" == \"c\" evaluiert wird, im Programmverlauf noch einmal verwenden. Dann wäre es unpraktisch, wenn wir jedes Mal den gesamten Ausdruck kopieren müssten. Wenn wir später die 3 durch eine 4 ersetzen, müssten wir dann alle Stellen finden, wo derselbe Ausdruck vorkommt, und überall die Änderung vornehmen. So entstehen schnell Fehler. Aus diesem Grund gibt es Variablen. Variablen ermöglichen, einen bestimmten Wert im Verlauf des Programms mehrmals zu verwenden, ohne ihn jedes Mal neu berechnen oder eingeben zu müssen. Werte können mithilfe der Zuweisungsoperatoren &lt;- und = einer Variable “zugewiesen” werden. Das heißt, dass ein Name festgelegt wird, der fortan für diesen Wert und für den Speicherplatz, in dem der Wert gespeichert wird, steht. Man kann alternativ auch sagen, dass ein Wert “an einen Namen gebunden” wird, oder andersherum, dass der Name einen bestimmten Wert “referenziert”. Eine Zuweisung folgt in R dem Schema Name &lt;- Wert. So kann mithilfe des Variablennamens auf den damit verknüpften Wert zugegriffen werden, selbst dann, wenn sich der Wert im Programmverlauf verändert hat. Variablen sind also sowas wie Platzhalter für Werte eines Datentyps. Bei der Benennung von Variablen sollten bestimmte Regeln und die Konventionen aus unserem Style Guide eingehalten werden: Variablennamen dürfen kein Leerzeichen enthalten (Regel!). Variablennamen dürfen keine Sonderzeichen außer Punkte und Unterstriche enthalten (Regel!). Zwei Wörter oder ein Wort und eine Zahl können mit Unterstrich, Punkt, oder camelCase getrennt werden. Wickhams Empfehlung ist hier die Verwendung des Unterstrichs. Variablen dürfen nicht mit einer Zahl oder einem Unterstrich anfangen (Regel!). R ist “case sensitive”, das heißt: die Variable baum ist nicht dasselbe wie die Variable Baum! Wickham empfiehlt, alle Variablennamen klein zu schreiben. Mit dem Zuweisungsoperator &lt;- bzw. = kann ein Wert einem Namen zugewiesen werden. &lt;- und = sind gleichbedeutend; Wickham empfiehlt aber die Verwendung des Operators &lt;-. Beim Ausführen einer Zuweisung wird nichts auf dem Bildschirm (auf der Rstudio Konsole) ausgegeben. Nach der Zuweisung können Werte, die einer Variable zugeordnet sind, mithilfe der Funktion print() auf dem Bildschirm ausgegeben werden. Alternativ kann auch einfach der Variablennamen erneut eingegeben und ausgeführt werden. # Zuweisungen zahl &lt;- 454 satz &lt;- &quot;Eine Rose ist eine Pflanze&quot; satz_2 &lt;- &quot;Eine zweite Rose ist auch eine Pflanze&quot; noch_ein_satz &lt;- &quot;Noch eine Rose&quot; Satz &lt;- &quot;Eine Rose ist keine Pflanze&quot; # Variable Satz auf dem Bildschirm ausgeben print(Satz) #&gt; [1] &quot;Eine Rose ist keine Pflanze&quot; # Variable satz auf dem Bildschirm ausgeben print(satz) #&gt; [1] &quot;Eine Rose ist eine Pflanze&quot; # Variable satz ohne die print()-Funktion auf dem Bildschirm ausgeben satz #&gt; [1] &quot;Eine Rose ist eine Pflanze&quot; # Der Variable satz einen neuen Wert zuweisen satz &lt;- &quot;Ein Apfel ist keine Pflanze&quot; # Variable satz erneut ausgeben print(satz) #&gt; [1] &quot;Ein Apfel ist keine Pflanze&quot; # hier werden die Variablen satz und Satz aus dem Beispiel oben verglichen satz == Satz #&gt; [1] FALSE Verständnisfragen: Welchen Datentyp hat die Variable zahl? Warum wird das erste Mal, dass die Anweisung print(satz) ausgeführt wird, ein anderer Wert ausgegeben, als beim zweiten Mal? Warum wird der Ausdruck satz == Satz zu FALSE evaluiert? Warum ist es nicht korrekt zu sagen, dass bei der Zuweisung ein Wert in einer Variable gespeichert wird? Wie könn die Ausdrücke 1 &gt; 2 &amp; 1 &lt; 4, 1 &gt; 2 | 1 &lt; 4 und (1 &lt; 4) == \"Hund\" mithilfe von Variablen so umgeschrieben werden, dass sich die Zahl 1 nicht wiederholt? Was passiert, wenn der Code 23 -&gt; zahl ausgeführt wird? Nicht nur einzelne Werte können Variablen zugewiesen werden, sondern auch ganze Ausdrücke. In der nächsten Stunde werden wir außerdem sehen, dass auch Datenstrukturen Variablen zugewiesen werden können. # Ausdrücke als Variablen aussage_1 &lt;- &quot;c&quot; == &quot;c&quot; aussage_2 &lt;- 3 == 5 aussage_1 == !aussage_2 #&gt; [1] TRUE Verständnisfragen: Was passiert in diesem Beispiel? Welcher Wert wird den Variablen aussage_1 und aussage_2 zugewiesen? Gut zu wissen: Eine Zuweisung ist eine Art von Anweisung: Sie beschreibt eine bestimmte Aktion, die vom Computer ausgeführt wird und die den Zustand des Speichers ändert. Deswegen sagt man, dass Anweisungen ausgeführt werden, während Ausdrücke ausgewertet werden. 1.7 Operatorpräzedenz Wir haben bereits einige Beispiele für Ausdrücke kennengelernt, die mehrere Operatoren beinhalten. Wie auch bei arithmetischen Operatoren gibt es bei allen anderen Operatoren eine festgelegte Reihenfolge, in der diese Operatoren ausgewertet werden, wenn sie im selben Ausdruck vorkommen und sich einen Operanden teilen. Für die bisher bekannten Operatoren gilt die folgende Rangfolge: Rang Operator 1 () 2 $ 3 [], [[]] 4 ^ 5 [:] 6 *, / 7 +, - 8 &lt;, &gt;, &lt;=, &gt;=, ==, != 9 ! 10 &amp;, &amp;&amp; 11 ⎮, ⎮⎮ 12 &lt;-, = Wenn diese Auswertungsreihenfolge geändert werden soll, müssen runde Klammern verwendet werden. Beispiele: 4 + 10 &gt; 3 + 5 * 2 #&gt; [1] TRUE 4 + 10 &gt; (3 + 5) * 2 #&gt; [1] FALSE FALSE &amp; TRUE == FALSE #&gt; [1] FALSE (FALSE &amp; TRUE) == FALSE #&gt; [1] TRUE Wenn zwei Operatoren in einem Ausdruck denselben Rang haben und einen Operanden teilen, wird der Ausdruck nach der sogenannten Assoziativität der Operatoren ausgewertet: wenn ein Operator linksassoziativ ist, dann heißt dass, dass ein Ausdruck von links nach rechts ausgewertet wird. Wenn ein Operator rechtsassoziativ ist, wird ein Ausdruck von rechts nach links ausgewertet. In R sind fast alle Operatoren linksassoziativ; nur der Potenzierungsoperator und der Zuweisungsoperartor sind rechtsassoziativ. Linksassoziatitvität: ((4+5)+6)+1 = (9+6)+1 = 15+1 = 16 Rechtsassoziativität: 3**(4**5) = 3**1024 = eine sehr lange Zahl Quellen Venables, W.N. and Smith, D.M. and the R Core Team (2023). An Introduction to R, https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf Wickham, Hadley. The Tidyverse Style Guide, https://style.tidyverse.org/ Wickham, Hadley (2019). Advanced R. Chapter 2: Names and Values, https://adv-r.hadley.nz/names-values.html Reussner, Ralf H. Mitschnitt zur Vorlesung “Programmieren” im WiSe 2015/2016. 02: Typen und Variablen, https://www.youtube.com/watch?v=POe41EL2EgU R 4.3.0 Documentation. Operator Syntax and Precedence, https://stat.ethz.ch/R-manual/R-devel/library/base/html/Syntax.html Wickham, Hadley (2019). Advanced R. Chapter 4: Subsetting, https://adv-r.hadley.nz/subsetting.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
